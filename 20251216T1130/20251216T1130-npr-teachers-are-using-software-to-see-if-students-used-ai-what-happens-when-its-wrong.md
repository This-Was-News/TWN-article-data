---
url: https://www.npr.org/2025/12/16/nx-s1-5492397/ai-schools-teachers-students
title: Teachers are using software to see if students used AI. What happens when it's
  wrong?
publisher: npr
usage: candidate
initial_rank: 5
---
## Article summary
Many teachers are using AI detection software to identify if students have used artificial intelligence for their assignments, despite research indicating these tools are unreliable. For instance, Ailsa Ostovitz, a high school junior, was accused of using AI on multiple assignments, even though she insists the work was her own. Her teacher's reliance on an AI detection tool led to a lowered grade, and her mother expressed concern over the premature accusations. While some school districts are spending significant amounts on these tools, like Broward County Public Schools investing over $550,000 in Turnitin, they acknowledge the software's inaccuracies. Companies like Turnitin themselves state that their AI detection should not be the sole basis for adverse actions against students. Educators like John Grady use GPTZero as a starting point for conversations, digging deeper if the tool flags more than 50% AI usage. However, critics, including students like Zi Shi and teachers like Carrie Cofer, question the efficacy and potential bias of these tools, suggesting the funds could be better allocated to teacher professional development. Cofer even found her own dissertation flagged as AI-generated. The consensus among skeptics is that these tools can produce false alarms and that educators must adapt by changing teaching and assessment methods rather than solely relying on AI detection. Students like Ostovitz are now preemptively running their work through multiple AI detectors to avoid potential flagging, adding extra time to their assignments.
